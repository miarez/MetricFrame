MetricFrame / Query Language ‚Äî Project Roadmap

A modern, opinionated data manipulation language inspired by dplyr, pandas, and SQL ‚Äî designed for analysts, BI teams, and performance marketing workflows.

‚∏ª

üìå Vision Statement

Build a columnar-first, functional, immutable-by-default data manipulation engine and DSL that:
‚Ä¢ works like dplyr (clean chaining, pure transformations)
‚Ä¢ feels like pandas (flexible, expressive)
‚Ä¢ integrates like SQL (joins, pivots, aggregation)
‚Ä¢ supports business logic layers (metric registries)
‚Ä¢ supports materialized views (cached or computed on demand)
‚Ä¢ allows R-style interactive workflow (run-by-cursor)
‚Ä¢ supports reactive pipelines (downstream refreshes)
‚Ä¢ is backend-agnostic and eventually can use faster engines under the hood (JS ‚Üí Python ‚Üí Rust/C++).

This is not ‚Äújust a dataframe library.‚Äù
It‚Äôs a full data experience layer.

‚∏ª

1. Language Core (DSL)

The core syntax is based on chainable transformations:

mf.read_csv("raw.csv")
.select("date", "source", "revenue", "profit")
.filter(Column.gt("revenue", 0))
.calc({ margin: sub("revenue", "cost") })
.group("date", "source")
.agg({ revenue: sum("revenue"), margin: mean("margin") })
.order("-date", "source")
.limit(500)
.build();

Core verbs (implemented)
‚Ä¢ read_csv, read_json
‚Ä¢ select(...)
‚Ä¢ filter(...)
‚Ä¢ calc({...}) ‚Äî row-wise column creation
‚Ä¢ group(...)
‚Ä¢ agg({...}) ‚Äî column reductions
‚Ä¢ order(...) / orderBy(...) (with -col for descending)
‚Ä¢ limit(...)
‚Ä¢ build()

Planned core verbs
‚Ä¢ distinct()
‚Ä¢ dropNA()
‚Ä¢ fillNA()
‚Ä¢ cast("col", "type")
‚Ä¢ rename({ old: new })
‚Ä¢ sample(n | frac)
‚Ä¢ replace(...)
‚Ä¢ pluck("col")

‚∏ª

2. Column-Level Function System

A strict separation:

‚úî Scalar Functions

operate on single values
Used inside user-defined functions or manual filter callbacks.
Defined in Scalar.js as static methods.

Examples:
Scalar.add(a,b), Scalar.abs(x), Scalar.gt(a,b), Scalar.bucket(x, bins, labels)‚Ä¶

‚∏ª

‚úî Column Functions

return wrappers describing how to apply scalar functions across a dataset.
Used inside .calc() and .filter().

Examples:

calc({
margin: sub("revenue", "cost"),
month_short: substr("month", 0, 3),
label: concat("country", "source", { sep: " - " })
})

These produce descriptors, not values.
The engine resolves them row-by-row.

‚∏ª

3. Aggregation Builder

A unified, extensible aggregation system:
‚Ä¢ declarative column-based use: sum("revenue")
‚Ä¢ structural use: { gp: sum, revenue: mean("revenue") }
‚Ä¢ consistent metadata and column resolution rules

Long-term:
‚Ä¢ window functions
‚Ä¢ ranks, percentiles
‚Ä¢ multi-pass aggregations

‚∏ª

4. Metric Registry

A layered, override-friendly system for reusable business logic:

Motivation:
‚Ä¢ Avoid rewriting GP, margin, CPC, CTR, etc.
‚Ä¢ Share metrics across teams.
‚Ä¢ Allow vertical overrides (global ‚Üí jobs ‚Üí jobs/region).
‚Ä¢ Track versions to avoid silent changes.

Structure:
‚Ä¢ global/metrics.js
‚Ä¢ jobs/metrics.js
‚Ä¢ promos/metrics.js

Metrics have:

{
version: "2.1.0",
scope: "jobs",
description: "...",
apply(df) { ... }
}

Planned features:
‚Ä¢ Layered inheritance (...spread)
‚Ä¢ MetricRegistry.forScope("jobs/ca")
‚Ä¢ metric version diff when report opens
‚Ä¢ metric descriptions + lineage

‚∏ª

5. Materialized Views (Cached Computations)

A system for snapshotting precomputed dataframes with TTLs and fallback:

view("jobs/gp_by_source_today", {
ttl: "1h",
compute: () => { ... MetricFrame chain ... },
});

Calling:

const df = await useView("jobs/gp_by_source_today");

gives:
‚Ä¢ cached df if fresh
‚Ä¢ or recomputes via compute() if expired

Goals:
‚Ä¢ reduce repeated heavy transforms
‚Ä¢ allow whole teams to share prepared datasets
‚Ä¢ keep dashboards consistent
‚Ä¢ avoid ‚Äúsurprise stale‚Äù with TTL + freshness constraints

Planned view features:
‚Ä¢ TTL-aware view caching
‚Ä¢ snapshot metadata storage
‚Ä¢ freshness indicators in downstream reports
‚Ä¢ invalidation + refresh commands

‚∏ª

6. Reactive Workspace (R-style Local Memory)

A core innovation:
Named transformations with dependency graphs.

Define:

ws.define("df_raw", () => mf.read_csv("raw.csv"));
ws.define("df", ({ df_raw }) => df_raw.filter(...).calc(...));
ws.define("top_n", ({ df }) => df.group(...).agg(...).limit(10));
ws.define("chart", ({ top_n }) => buildChart(top_n));

Use:

ws.get("chart");

Modify df logic ‚Üí auto-recompute downstream:

ws.refreshDownstream("df");
ws.get("chart"); // updated chart

This is effectively a local DAG engine inside your data language,
allowing for:
‚Ä¢ interactive prototyping
‚Ä¢ hot-reloads
‚Ä¢ stateful exploratory analysis

Inspired by:
RStudio + dbt + Airflow + spreadsheets.

‚∏ª

7. Interactive Runtime (R-style)

A major design choice:

‚úî One script file
‚úî Run-block-by-cursor
‚úî Long-lived runtime
‚úî Workspace memory
‚úî No Jupyter notebook blocks
‚úî No global cells that fall out of sync

This mode allows analysts to:
‚Ä¢ experiment fast
‚Ä¢ run just the part they are editing
‚Ä¢ keep dfs in memory
‚Ä¢ reuse upstream results

Core planned features:
‚Ä¢ VS Code extension or command ‚ÄúRun selection in MetricFrame Runtime‚Äù
‚Ä¢ Persistent REPL process
‚Ä¢ Inspect memory (workspace.ls())
‚Ä¢ Delete/refresh objects
‚Ä¢ Print previews (df.head())

‚∏ª

8. Future Execution Engines

MetricFrame is intentionally backend-agnostic.

The plan:

Stage 1 (now)
‚Ä¢ JS-only execution in Node
‚Ä¢ fully eager
‚Ä¢ JSON/CSV I/O

Stage 2
‚Ä¢ optional lazy planner
‚Ä¢ pluggable execution backends

Backends may include:
‚Ä¢ Python (pandas, polars)
‚Ä¢ Rust (polars native)
‚Ä¢ DuckDB for local SQL execution
‚Ä¢ WebAssembly bundles
‚Ä¢ Cloud database pushdowns

The DSL stays the same.
The engine changes under the hood.

‚∏ª

9. Perf Marketing‚ÄìSpecific Enhancements

Since one of the first real verticals is performance marketing:

Plans:
‚Ä¢ built-in topN + bucketization helpers
‚Ä¢ concentration analysis (Herfindahl, pareto)
‚Ä¢ attribution helpers
‚Ä¢ source dominance detection
‚Ä¢ auto-facet detection
‚Ä¢ ‚ÄúOther‚Äù category collapsing
‚Ä¢ time-window join helpers
‚Ä¢ snapshot view patterns:
‚Ä¢ daily top sources
‚Ä¢ yesterday vs last week KPIs
‚Ä¢ alerting on metric changes

‚∏ª

10. Long-Term Roadmap (Chronological Rough Order)

Phase 1 ‚Äî Solidify core
‚Ä¢ Immutable Pipeline
‚Ä¢ Better error messages
‚Ä¢ Finish Column functions
‚Ä¢ Finish Aggregation builder
‚Ä¢ Add missing core verbs (distinct, pivot, joins, etc.)

Phase 2 ‚Äî Metric Framework
‚Ä¢ Metric Registry
‚Ä¢ Metric validation + versioning
‚Ä¢ Diff on load

Phase 3 ‚Äî Views
‚Ä¢ View registry
‚Ä¢ Snapshot caching
‚Ä¢ TTL + freshness + fallback

Phase 4 ‚Äî Workspace Runtime
‚Ä¢ Reactive DAG workspace
‚Ä¢ VS Code integration
‚Ä¢ Run-by-cursor
‚Ä¢ Inspect & refresh commands

Phase 5 ‚Äî Execution Engine Expansion
‚Ä¢ Lazy query planner
‚Ä¢ Backend adapters (Python/Rust/SQL)

Phase 6 ‚Äî Polishing / UX
‚Ä¢ Reproducible reports
‚Ä¢ Rendering helpers (tables / charts)
‚Ä¢ API docs + examples

‚∏ª

11. High-Level End Goal

A full data manipulation environment that:
‚Ä¢ lets analysts express transformations clearly
‚Ä¢ lets BI folks share formulas safely
‚Ä¢ lets devs connect backends flexibly
‚Ä¢ unifies SQL / pandas / dplyr concepts
‚Ä¢ can power dashboards, scripts, reports, and pipelines
‚Ä¢ can scale up or down
‚Ä¢ works interactively and in production

All while having one north star:

Make data transformation simple, predictable, explicit, sharable, and fast.

‚∏ª

If you want, I can create a matching CONTRIBUTING.md, directory structure proposals, or a ‚ÄúMetricFrame Philosophy‚Äù doc.
